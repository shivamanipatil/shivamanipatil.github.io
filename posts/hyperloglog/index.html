<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>HyperLogLog - Shivamani Patil</title><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="Table of contents Streaming algorithm and sketching algorithms Count Distinct problem Hyperloglog(HLL) HLL improvements Demo Streaming and sketching algorithms Algorithms for data streams that examine data a few times and have low memory requirements. Storing individual elements is not possible in data streams as in most cases the size is enormous. We try to get approximate or &ldquo;good enough&rdquo; estimates while storing the &ldquo;sketch&rdquo; of the data(i.e some representation of data) but not the data itself."><meta property="og:image" content><meta property="og:title" content="HyperLogLog"><meta property="og:description" content="Table of contents Streaming algorithm and sketching algorithms Count Distinct problem Hyperloglog(HLL) HLL improvements Demo Streaming and sketching algorithms Algorithms for data streams that examine data a few times and have low memory requirements. Storing individual elements is not possible in data streams as in most cases the size is enormous. We try to get approximate or &ldquo;good enough&rdquo; estimates while storing the &ldquo;sketch&rdquo; of the data(i.e some representation of data) but not the data itself."><meta property="og:type" content="article"><meta property="og:url" content="https://shivamanipatil.github.io/posts/hyperloglog/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-17T00:00:00+00:00"><meta property="article:modified_time" content="2022-05-17T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="HyperLogLog"><meta name=twitter:description content="Table of contents Streaming algorithm and sketching algorithms Count Distinct problem Hyperloglog(HLL) HLL improvements Demo Streaming and sketching algorithms Algorithms for data streams that examine data a few times and have low memory requirements. Storing individual elements is not possible in data streams as in most cases the size is enormous. We try to get approximate or &ldquo;good enough&rdquo; estimates while storing the &ldquo;sketch&rdquo; of the data(i.e some representation of data) but not the data itself."><script src=https://shivamanipatil.github.io/js/feather.min.js></script><link href=https://shivamanipatil.github.io/css/fonts.b685ac6f654695232de7b82a9143a46f9e049c8e3af3a21d9737b01f4be211d1.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://shivamanipatil.github.io/css/main.2f9b5946627215dc1ae7fa5f82bfc9cfcab000329136befeea5733f21e77d68f.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://shivamanipatil.github.io/css/dark.726cd11ca6eb7c4f7d48eb420354f814e5c1b94281aaf8fd0511c1319f7f78a4.css media="(prefers-color-scheme: dark)"><script async src="https://www.googletagmanager.com/gtag/js?id=G-44FM66QXX5"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-44FM66QXX5")</script></head><body><div class=content><header><div class=main><a href=https://shivamanipatil.github.io/>Shivamani Patil</a></div><nav><a href=/>Home</a>
<a href=/posts>All posts</a>
<a href=/open-source>Open Source</a>
<a href=/about>About</a></nav></header><main><article><div class=title><h1 class=title>HyperLogLog</h1><div class=meta>Posted on May 17, 2022</div></div><section class=body><h2 id=table-of-contents>Table of contents</h2><ol><li>Streaming algorithm and sketching algorithms</li><li>Count Distinct problem</li><li>Hyperloglog(HLL)</li><li>HLL improvements</li><li>Demo</li></ol><h2 id=streaming-and-sketching-algorithms>Streaming and sketching algorithms</h2><ul><li>Algorithms for data streams that examine data a few times and have low memory requirements.</li><li>Storing individual elements is not possible in data streams as in most cases the size is enormous.</li><li>We try to get approximate or &ldquo;good enough&rdquo; estimates while storing the &ldquo;sketch&rdquo; of the data(i.e some representation of data) but not the data itself. The &ldquo;sketch&rdquo; size should be much less than the data size.</li><li>In short, we are doing a tradeoff between accuracy and memory.</li></ul><h2 id=count-distinct-problem>Count Distinct problem</h2><ul><li>Finding the number of unique/distinct elements in a multiset(set with repeated elements).</li><li>e.g., unique visitors to a website and unique IP addresses through a router.</li><li>Simple solution to this could be to keep a map of every element and its count. The main drawback of this approach is the storage of the map, as in the worst case, it is O(n).</li><li>A sketching algorithm could prove helpful for this case as, in most cases, we would not care about 100% accuracy.</li></ul><h2 id=hyperlogloghll>Hyperloglog(HLL)</h2><p>Sketching algorithm designed to solve the count-distinct problem within acceptable error rate. Described in the paper &ldquo;HyperLogLog: the analysis of near-optimal cardinality estimation algorithm&rdquo;, published by Flajolet, Fusy, Gandouet and Meunier in 2007. Improvements were proposed in &ldquo;HyperLogLog in Practice: Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm&rdquo;, published by Stefan Heulem, Marc Nunkesse and Alexander Hall.</p><p>Based on simple obervation : <strong>On average, a sequence of k consecutive zeros in binary form of a number will occur once in every 2^k distinct entries.</strong> E.g. if we have a large enough collection of fixed-width numbers (e.g. 32/64/128 bit) and while going through it and we find a number starting with k consecutive zeros in binary form, we can be almost sure that there are at least 2^k numbers in that collection.</p><h3 id=simple-estimator>Simple Estimator</h3><ul><li>To keep the input data uniform and evenly distributed we use a hash function. Now each entry is of fixed width(e.g 32/64/128 bits).</li><li>While going through the collection we simply keep the count of longest consecutive sequence of zeros.</li><li>Example of simple estimator (credits : engineering.fb.com) :</li></ul><p><img src="https://engineering.fb.com/wp-content/uploads/2018/12/HLL31.png?resize=800,400" alt="Simple Estimator"></p><ul><li>We will define a <strong>counter/estimator</strong> as data structure which holds longest consecutive sequence of zeros for a collection ( R ).</li><li>So, according to our theory this estimator will give estimate/cardinality as E = 2^R.</li><li>Problem with this is that estimates will be only in powers of 2 and there can be lot of variability as only a single value having largest sequence of zeros can affect the total estimate.</li></ul><h3 id=multiple-estimators-and-hll>Multiple estimators and HLL</h3><p>To solve the issue faced by simple estimator we will use multiple estimators(let&rsquo;s say of m number) and divide the input collection between them. So, now each estimator has its own ( R ). We get single estimate using harmonic mean of individual estimates of counters.</p><p><img src=/hll-estimate.PNG alt=Equation></p><p>A estimator is basically just a register or a single variable holding longest sequence of consecutive zeros. Each estimator can be thought of as a bin. So we have m bin i.e m registers (or just array of size m really) to imitate m estimator.</p><p>To divide the input collection between the m estimators we can reserve some starting bits of hashed value for bin index and rest bits for counting longest sequence of consecutive zeros.</p><p>Illustration of this (credits : engineering.fb.com) :
<img src="https://engineering.fb.com/wp-content/uploads/2018/12/HLL5.png?resize=800,400" alt="Bin buckets"></p><p>This is the basis of the hyperloglog algorithm. The algorithm described in the paper with some error corrections is as follows idea behind it remains same though :</p><p><img src=/hll-original.PNG alt="Hyperloglog algo">.</p><h3 id=hll-parameters-and-storage-analysis>HLL parameters and storage analysis</h3><p><img src=/hll-param-storage.png alt=storage-image></p><p>From above illustration we can clearely see that only 12 KB storage is required for a very large ndistinct value and relatively small error rate.</p><h2 id=hll-improvements>HLL improvements</h2><p>Improvements were proposed in &ldquo;HyperLogLog in Practice: Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm&rdquo;, published by Stefan Heulem, Marc Nunkesse and Alexander Hall :</p><ol><li>Using 64 bit hash function</li><li>Estimating small cardinalities</li><li>Sparse representation</li></ol><h3 id=64-bit-hash-function>64 bit hash function</h3><p>Hash function with L bits will distinguish at most 2^L values. Beyond 4 billion unique entries 32 bit hash function wouldn&rsquo;t be
useful. 64 bit hash function would be usable till 1.8 * 10^19 cardinalities (which should suffice for all cases).</p><p><img src=/hll-hash-comp.PNG alt=hash-compare></p><p>Here you can see size increased by just m bits or 2 KB(if m = 2^14 with error=0.008125).</p><h3 id=estimating-small-cardinalities>Estimating small cardinalities</h3><p>Raw estimate of original hll algorithm gives large error for small cardinalities. To reduce the error original algorithm uses linear counting for cardinalities less than 5*m/2.</p><p><a href=https://storage.googleapis.com/pub-tools-public-publication-data/pdf/40671.pdf>Improvement paper</a> found out that the error for small cardinalities is due to a bias(i.e algorithm overestimates the cardinalities). They also could correct the bias by precomputing the bias values and substracting them from the raw estimate.</p><p><img src=/hll-bias.PNG alt=bias></p><p>This figure from <a href=https://storage.googleapis.com/pub-tools-public-publication-data/pdf/40671.pdf>Improvement paper</a> shows the bias for raw estimate. Also, it shows linear counting is still better than bias-correction for smaller cardinalities.</p><p>From this they concluded to perform linear counting till 11500 for p = 14 and bias correction after that.</p><h3 id=sparse-representation>Sparse representation</h3><p>When n &#171; m, then most of the bins(2^14 if p=14) are empty and memory is wasted. So instead we can store just pairs of (idx, R) values (idx - index of bin, R - longest consecutive zeros sequence observed by that bin).</p><p>And when size of these pairs increases than the normal(dense) mode of m bins then we can convert to the normal(dense) mode. Thing to note is that we can merge pairs with same idx and keep just the pair with largest R.</p><h2 id=demo>Demo</h2><p>For the demo I will be using <a href=https://github.com/conversant/postgres_hyperloglog>postgress_hyperloglog</a>. This is a postgreSQL extension implementing hyperloglog estimator. You can follow the installation steps from the repo README.</p><h3 id=example-1>Example 1:</h3><p><img src=/hll-example1.png alt=example1></p><p>Here, we are generating 1,10000 series and then doing hyperloglog_distinct aggregate on these.
hyperloglog_distinct aggregate just creates a hll estimator, adds column elements and returns the estimate.
The hll estimates 9998.401034851891 which is pretty close to 10000 cardinality.</p><h3 id=example-2>Example 2:</h3><p>You can serialize these estimators, save them and load them again to operate on later.</p><p><img src=/hll-accum1.png alt=example2>
<img src=/hll-accum2.png alt=example2></p><p>hyperloglog_accum - creates hll estimator, adds column elements and returns the serialized estimator.
Output in second picture is actually base64 encoded byte string of the estimator.</p><h3 id=example-3>Example 3:</h3><p>We can also get estimate from this accumulated result(example 2).</p><p><img src=/hll-estimate2.png alt=example3></p><p>Internal hll data structure is binary compatible with base64 encoded byte string - so they are interoperable. This way we can perform hyperloglog_get_estimate operation on the hll estimator returned by hyperloglog_accum.</p><p>For other examples you can refer to <a href=https://github.com/conversant/postgres_hyperloglog/tree/master/test/sql>sql references</a> and try it out yourself.</p><p>References :</p><ol><li>&ldquo;HyperLogLog: the analysis of near-optimal cardinality estimation algorithm&rdquo;, published by Flajolet, Fusy, Gandouet and Meunier</li><li>&ldquo;HyperLogLog in Practice: Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm&rdquo;, published by Stefan Heulem, Marc Nunkesse and Alexander Hall</li><li><a href=https://engineering.fb.com/2018/12/13/data-infrastructure/hyperloglog/>https://engineering.fb.com/2018/12/13/data-infrastructure/hyperloglog/</a></li><li><a href=https://github.com/conversant/postgres_hyperloglog>https://github.com/conversant/postgres_hyperloglog</a></li></ol></section><div class=post-tags></div></article></main><footer><hr><a class=soc href=https://github.com/shivamanipatil title=GitHub><i data-feather=github></i></a>|<a class=soc href=https://twitter.com/ShivamaniPatil_ title=Twitter><i data-feather=twitter></i></a>|⚡️
2023 <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></footer><script>feather.replace()</script></div></body></html>