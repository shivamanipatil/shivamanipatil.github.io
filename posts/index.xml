<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Shivamani Patil</title><link>https://shivamanipatil.github.io/posts/</link><description>Recent content in Posts on Shivamani Patil</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 17 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://shivamanipatil.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>HyperLogLog</title><link>https://shivamanipatil.github.io/posts/hyperloglog/</link><pubDate>Tue, 17 May 2022 00:00:00 +0000</pubDate><guid>https://shivamanipatil.github.io/posts/hyperloglog/</guid><description>Table of contents Streaming algorithm and sketching algorithms Count Distinct problem Hyperloglog(HLL) HLL improvements Demo Streaming and sketching algorithms Algorithms for data streams that examine data a few times and have low memory requirements. Storing individual elements is not possible in data streams as in most cases the size is enormous. We try to get approximate or &amp;ldquo;good enough&amp;rdquo; estimates while storing the &amp;ldquo;sketch&amp;rdquo; of the data(i.e some representation of data) but not the data itself.</description></item><item><title>Spark aggregation with native API's</title><link>https://shivamanipatil.github.io/posts/spark-agg/</link><pubDate>Thu, 24 Feb 2022 00:00:00 +0000</pubDate><guid>https://shivamanipatil.github.io/posts/spark-agg/</guid><description>Table of contents Spark aggregation Overview TypedImperativeAggregate[T] abstract class Example Spark aggregation Overview User Defined Aggregate Functions can be used. But are restrictive and require workarounds even for basic requirements. Aggregates are unevaluable expressions and cannot have eval and doGenCode method. Basic requirement would be to use user defined java objects as internal spark aggregation buffer type. And, passing extra arguments to aggregates e.g aggregate(col, 0.24) Spark provides TypedImperativeAggregate[T] contract for such requirement (imperative as in expressed in terms of imperative initialize, update, and merge methods).</description></item><item><title>Spark Catalyst Optimizer and spark Expression basics</title><link>https://shivamanipatil.github.io/posts/spark-catalyst/</link><pubDate>Wed, 23 Feb 2022 00:00:00 +0000</pubDate><guid>https://shivamanipatil.github.io/posts/spark-catalyst/</guid><description>Table of contents Overview Trees Rules Expression CodegenFallback Example of spark native function using Unary expression Spark Catalyst Overview Core of Spark dataframe API and SQL queries. Supports cost based and rule based optimization. Built to be extensible : Adding new optimization techniques and features Extending the optimizier for custom use cases At core it uses trees On top of it various libraries are written for query processing, optimization and execution.</description></item><item><title>Traffic flow in Kubernetes 101</title><link>https://shivamanipatil.github.io/posts/k8s-networking/</link><pubDate>Sun, 16 Jan 2022 00:00:00 +0000</pubDate><guid>https://shivamanipatil.github.io/posts/k8s-networking/</guid><description>Table of contents Intra pod communication Inter pod communication CNI plugin Pod to service communication Intra pod communication When pod is created,
It is assigned to a node. A network namespace is created for it(i.e all of that pod&amp;rsquo;s containers belong to that namespace), IP is assigned to it. For every pod in the cluster there is pause container running in the background. The pause container creates and holds network namespace for that pod.</description></item><item><title>GSoC 2020 Report</title><link>https://shivamanipatil.github.io/posts/gsoc/</link><pubDate>Sun, 30 Aug 2020 00:00:00 +0000</pubDate><guid>https://shivamanipatil.github.io/posts/gsoc/</guid><description>Introduction During my GSoC, I worked on App Store improvements project for ns-3 organization. GSoC was my first programming experience outside personal projects and I thoroughly enjoyed the experience. I had an awesome opportunity to work for the ns-3 organization. My mentors abhijithanilkumar, mishalshah and adeepkit01 were extremely responsive, helpful, and understanding. I would also like to thank tomh sir - the ns-3 Organization Admin for his help and suggestions.</description></item><item><title>Integrating Elasticsearch 7 to Django project</title><link>https://shivamanipatil.github.io/posts/shivamanipatil10/integrating-elasticsearch-7-to-django-project-c3812de78246/</link><pubDate>Wed, 18 Dec 2019 17:09:05 +0000</pubDate><guid>https://shivamanipatil.github.io/posts/shivamanipatil10/integrating-elasticsearch-7-to-django-project-c3812de78246/</guid><description>I had to migrate the Elasticsearch 2.x using django-haystack to latest Elasticsearch 7.5.0 for a project. Here the way I did it. You can also follow if you wish to use Elasticsearch for your django project. I will be using Django 2.1.5.
Haystack is great open-source package that provides modular search for Django.Unfortunately it doesnâ€™t support recent versions of Elasticsearch. So for migration to latest version of Elasticsearch we need to remove django-haystack package.</description></item></channel></rss>